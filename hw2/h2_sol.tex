\documentclass[a4paper,11pt]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage[headsepline]{scrlayer-scrpage}
\ihead{Bernd Schwarzenbacher}
\chead{CMSDE HW2}
\ohead{\today}

\usepackage{listings}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{commath}
\usepackage[makeroom]{cancel}
\usepackage[retainorgcmds]{IEEEtrantools}

\newcommand*{\dt}{\dif{}t}
\newcommand*{\dY}{\dif{}Y}
\newcommand*{\dX}{\dif{}X}
\newcommand*{\dW}{\dif{}W(t)}
\newcommand*{\Xb}{\bar{X}}

\newcommand*{\D}{\Delta}
\newcommand*{\E}{\mathbb{E}}
\newcommand*{\EV}[1]{\E\left[{#1}\right]}
\newcommand*{\Lt}[1]{\EV{\left({#1}\right)^2}}

\begin{document}

\begin{enumerate}
\item
For the following SDE
\begin{IEEEeqnarray*}{rCl}
    \dX(t) & = & a(t, X(t)) \dt + b(t, X(t)) dW \\
    X(0) & = & x_0
\end{IEEEeqnarray*}
I implemented the forward Euler approximation
\begin{IEEEeqnarray*}{rCl}
\Xb_{n+1} &=& \Xb_n + a(t_n, \Xb_n) \D t + b(t_n, \Xb_n) \D W_n \\
\Xb_0 &=& x_0
\end{IEEEeqnarray*}

To make computing the strong error
\[ \norm{X(T) - \Xb(T)}_{L^2(\Omega)} = \sqrt{\EV{(X(T) - \Xb(T))^2}} \]
easier, I use a SDE with a known analytical solution, namely the geometric
Brownian motion satisfying the SDE:
\begin{IEEEeqnarray*}{rCl}
    \dX(t) & = & \mu X(t) \dt + \sigma X(t) dW
\end{IEEEeqnarray*}
with $\mu$ and $\sigma$ constant.

The weak error is defined as
\[ \EV{g(X(T))} - \EV{g(\Xb(T))}\]
I evaluated the weak error for the following functions:
\[g_1(x) = e^{-x^2/2}, \quad g_2(x) = x, \quad g_3(x) = \frac{1}{\sqrt{|x - 5 \sigma|}}\]

I simulated with $10^5$ samples per Monte Carlo approximation.
For the plots I used $\mu = \sigma = 1$.

The first graph shows the strong error together with a fitted square root function:
\begin{figure}[h]
  \centering
\includegraphics[width=0.5\textwidth]{strong_error.pdf}
\caption{Strong error square root convergence}
\label{fig:strong}
\end{figure}
We see in~\figref{fig:strong}, that the error declines with $O(\sqrt{\D t})$ as predicted by Theorem 3.1.

  \begin{figure}
  \centering
    \includegraphics[width=0.5\textwidth]{weak_error1.pdf}
    \caption{Weak error for $g_1$ with linear convergence}
  \end{figure}
  \begin{figure}
  \centering
    \includegraphics[width=0.4\textwidth]{weak_error2.pdf}
    \caption{Linear weak error convergence although $\lim_{x\rightarrow\infty}g_2(x) \neq 0$}
  \end{figure}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{weak_error3.pdf}
  \caption{No convergence because $g_3 \notin L^2$}
\end{figure}
\pagebreak

\item
\begin{enumerate}
\item
  We use the diagonalization of $A = T^{-1} \Lambda T$, where $T$ is an
  invertible matrix and $\Lambda~=~\text{diag}(\lambda_1, \lambda_2)$ is the
  diagonal matrix of eigenvalues. Further we will only consider the transformed
  system
  \[\dY_t = \Lambda Y_t \dt, \quad \text{with } Y_t = T X_t\]
  To obtain the exact solution, the system can now be solved separately for each component.
  \begin{IEEEeqnarray*}{rCl}
    y_1(t) &=& e^{\lambda_1 t} = e^{t} \\
    y_2(t) &=& e^{\lambda_2 t} = e^{-10^5 t}
  \end{IEEEeqnarray*}
  Using a method for this system is like solving two 1-dimensional ODE's with the same method.
  For each component the backwards Euler method gives:
  \[ y_{n+1} = y_n + \lambda y_{n+1} \D t \Rightarrow y_{n+1} = \frac{1}{1 - \lambda \D t}
    y_n = g(\lambda \D t) y_n \]

  The function $g(z) = \frac{1}{1 - z}$ is called the stability function.

  In contrast for the forward Euler method we get $g(z) = 1 + z$:
  \[ y_{n+1} = y_n + \lambda y_n \D t = (1 + \lambda \D t) y_n \]
  With the stability function we can generally express the discrete solution
  in dependence of the start value as \[y_n = g(\lambda \D t)^n y_0\]

  So in the case of forward Euler we will get oscillating and exploding
  solutions for $\lambda \D t < -1$.
  Therefore to solve the second component we would need a step size of $\D t < 10^{-5}$, which
  is then excessively small for the first component.

  The backward Euler methods gives a decreasing solution for the second equation
  even for big step sizes and to get an increasing solution for the first
  equation we need $\lambda_1 \D t < 1$, so in our case $\D t < 1$ which is feasible.
\item
  For the SDE
  \[\dX = a X_t \dt + b X_t \dW_t\]
  we formulate following method: apply backwards Euler for the drift part and
  forward Euler for the diffusion term.
  The heuristic is to to get similar behavior as in 2a) for the drift part and
  still obtain an It\^{o} integral for the diffusion term:
  \[X(t_{n+1}) - X(t_n) = a X(t_{n+1}) \D t + b X(t_n) \D W \]
  With this idea the update is explicitly given by:
  \[X(t_{n+1}) = \frac{1 + b \D W}{1 - a \D t} X(t_n)\]

  We will compare it to the complete forward Euler discretization, for which we
  know convergence in $L^2$ from Theorem 3.1.
  \[\Xb(t_{n+1}) = (a \D t + b \D W) \Xb(t_n)\]
  Let's compute the $L^2$-difference of the two methods:
  \[\Lt{\Xb(t_{n+1}) - X(t_{n+1})} = \Lt{a \D t + b \D W - \frac{b \D W + 1}{1 - a \D t}}
    \Lt{\Xb(t_{n}) - X(t_n)} \]
  \[ = \Lt{\frac{a \D t - a^2 \D t^2 +\cancel{b \D W} - a b \D t \D W -\cancel{b \D
       W} + 1}{1 - a \D t}}
    \Lt{\Xb(t_{n}) - X(t_n)} \]
  Squaring and using $\EV{\D W} = 0$ as well as $\EV{(\D W)^2} = \D t$:
  \[ = \frac{\cancel{a^2 \D t^2} - 2 a^3 \D t^3 + a^4 \D t^4 +
     2 a \D t -\cancel{a^2 \D t^2} -2 a^2 b^2 \D t^3 + 1}{(1 - a \D t)^2}
     \Lt{\Xb(t_n) - X(t_n)}
  \]

Now the fraction is bounded for some small $c \geq \D t \geq 0$, where c is
dependent on $a < 0$ and $b > 0$.

By assuming \[ \Lt{\Xb(t_0) - X(t_0)} \leq K \D t \]
we get $L^2$-equivalence of the methods in the limit $\D t \rightarrow 0$.
\end{enumerate}
\end{enumerate}

Please find the following code for exercise 1 online at:

\url{https://github.com/bschwb/cmsde/hw2/exercise1.py}

\lstinputlisting{exercise1.py}

\end{document}