\documentclass[a4paper,11pt]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage[headsepline]{scrlayer-scrpage}
\ihead{Bernd Schwarzenbacher}
\chead{CMSDE HW5}
\ohead{\today}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{commath}
\usepackage{mathtools}
\usepackage[retainorgcmds]{IEEEtrantools}

\usepackage{hyperref}
\usepackage[noabbrev]{cleveref}
\usepackage{float}
\usepackage{graphicx}

\newcommand*{\R}{\mathbb{R}}
\newcommand*{\EV}[1]{\mathbb{E}\left[{#1}\right]}
\newcommand*{\bt}{\bold{\theta}}

\begin{document}

\begin{enumerate}

\item
  Running the code, I get an accuracy of $0.9455$.

\item
  The accuracy turned out to be worse: $0.938$.

\item
  With the Adam optimizer, I get an accuracy of $0.9423$.
  Doubling the number of iterations $M$ to $10000$ we finally get an improved
  accuracy of $0.9503$.

\item
  The new optimization problem is
  \[ \min_{\bt \in \R^{(784+1)\times K + 2 (K+1) \times K + 10 \times K}} \EV{H(y(X), S(\alpha_\bt(X)))}\]
  for the random handwritten digit $X \in \R^{784}$. The neural network
  $\alpha_\bt(x)$ with 3 hidden layers, where each hidden layer has $K$ units plus a bias unit.
  It can be written as:
  \[ \alpha_\bt(x) = r(\Theta_3 r(\Theta_2 r(\Theta_1 x + \theta_1) + \theta_2)
    + \theta_3) x \in \R^{784} \]

  with the ReLU activation unit:
  \[ r(x) = \max(0, x)\]

  The accuracy only improved a little bit to $0.9559$.


\item

\item


\end{enumerate}

\section*{Code Appendix}

All code can be found online at
\url{https://github.com/bschwb/cmsde/tree/master/hw5}

% \lstset{caption={Code for 1b}, label=lstex1b}
% \lstinputlisting{exercise1b.py}

% \lstset{caption={Code for 2g}, label=lstex2g}
% \lstinputlisting{exercise2g.py}

\end{document}